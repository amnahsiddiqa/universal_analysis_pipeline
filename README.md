# Universal data analysis pipeline
Nextflow-based pipeline to run and deploy reproducible analyses.

## Features
* render jupyter notebooks or Rmarkdown notebooks (papermill/knitr)
* ensure reproducible analyses
* deploy reports to GitHub pages.

## Structure

* `deploy`: final reports. will be uploaded to Github pages
* `nextflow`: nextflow modules
* `lib`: put custom libraries (e.g. python modules)  here
* `notebooks`: The actual analysis steps (i.e. jupyter notebooks, Rmarkdown
  documents) go here.
* `data`: input data.
* `tables`: manually created input data that I want to be under version control.
* `results`: final results generated by the pipeline go here. Concept: one can
  always delete the results directory and re-generate it from `data` using the
  pipeline.


## Configuration
* github URL
* access token
* plug togehter analysis steps.


## Ideas
* convert conda envs to singularity containers to ensure reproducibility.
