# Universal data analysis pipeline
[![Build Status](https://travis-ci.com/grst/universal_analysis_pipeline.svg?branch=master)](https://travis-ci.com/grst/universal_analysis_pipeline)

Nextflow-based pipeline to run and deploy reproducible analyses.

## Features
* render jupyter notebooks or Rmarkdown notebooks (papermill/knitr)
* ensure reproducible analyses
* deploy reports to GitHub pages.

## Structure

* `bin`: scripts that can be called from nextflow. Currently contains scripts to render notebooks into HTML.
* `data`: input data for the notebooks. I often replace this with a symlink to some data storage. 
* `deploy`: final reports. will be generated by `.deploy.sh` and uploaded to Github pages
* `envs`: conda environment files go here. Create one file per notebook, or re-use environments for multiple notebooks - it's up to you. 
* `lib`: put custom libraries (e.g. python modules) here. 
* `nextflow`: If you create nextflow modules, put them here. 
* `notebooks`: The actual analysis steps (i.e. jupyter notebooks, Rmarkdown
  documents) go here.
* `results`: final results generated by the pipeline go here. Concept: one can
always delete the results directory and re-generate it from `data` using the
pipeline.
* `tables`: manually created input data that I want to be under version control. E.g. the list of samples and the associated patient data that you had to compile manually from three excel sheets because the biologists used colors to represent actual data. 

  
## How to run. 
1. Install nextflow 
In this case, we use conda. Check the nextflow webiste for other options. 
```
conda create -n nextflow -c conda-forge -c bioconda nextflow
conda activate nextflow
```

2. Clone this repository
```
gitclone git@github.com:grst/universal_analysis_pipeline.git
cd universal_analysis_pipeline
```

3. Run the pipeline
```
./main.nf
```

4. Deploy the results on github pages. 

The results will be protected by a randomly generated folder name. It is stored in `.access_token`. 
```
./deploy.sh
```


  
## How to use
This repository is meant as a template. You can fork/clone this repository 
and expand from there. At least, you have to change two things: 
* Add your notebooks to the `notebooks` folder
* Edit `main.nf` to wire your notebooks together the right way. Feel free to use either the `render_rmd.py` or `render_papermill.py` wrapper scripts to render the notebooks. 




## Ideas for the future: 
* convert conda envs to singularity containers to ensure reproducibility.
